# Flow-only baseline configuration for CIFAR-10
# Freeze AR transformer and train flow with Gaussian prior (no AR)

vocab_size: 32000

# Image/tokenization (CIFAR-10 specific)
input_size: [32, 32]
patch_size: 2
image_ar_dim: 12
num_mixtures: 512
use_bfloat16_img_head: true
channel_repeat: 0

# Flow (Jet) â€” post-flow factoring
jet_depth: 24
jet_block_depth: 4
jet_emb_dim: 384
jet_num_heads: 6
flow_actnorm: true
flow_invertible_dense: false
latent_projection: null
pre_factor_dim: null  # keep POST-flow factoring

# AR Transformer (will be frozen for flow-only)
d_model: 512
n_heads: 8
n_layers: 12
d_ff: 2048
n_kv_heads: 1
dropout: 0.1
max_seq_len: 320  # 64 image tokens + class tokens + slack

# Conditioning (class-conditional CIFAR-10)
num_classes: 10
class_token_length: 8
cfg_drop_prob: 0.0  # No CFG for flow-only
cfg_strength: 0.0  # No CFG for flow-only
cfg_mode: "reject"

# Dataset / training target
dataset: cifar10

# Optimization / curriculum
batch_size: 2048
learning_rate: 0.001
warmup_percent: 0.1
use_cosine: true
weight_decay: 0.0
opt_b1: 0.9
opt_b2: 0.95
grad_clip_norm: 1.0
num_epochs: 400
precision: fp32
torch_compile: false
grad_checkpoint_transformer: false
flow_grad_checkpoint: false

# EMA
ema:
  enabled: false

# Noise curriculum (important for flow training)
rgb_sigma0: 0.0
rgb_sigma_final: 0.0
noise_curriculum_epochs: 0
latent_noise_std: 0.0  # No latent noise for flow-only
text_loss_weight: 0.0
image_loss_weight: 1.0
grad_accum_steps: 1

# Flow-only specific settings
flow_only_mode: true  # New flag to enable flow-only training
freeze_transformer: true  # Freeze AR transformer params
gaussian_prior_for_ar: true  # Use Gaussian prior instead of AR predictions

# Epoch-level schedules
sample_every_epochs: 5
val_every_epochs: 5

# Evaluation controls
eval_no_rgb_noise: true
fid_every_epochs: 0
is_every_epochs: 0
fid_is_num_samples: 0
advanced_metrics: true

# Dataloader / augmentation
num_workers: 8
max_samples: null
ignore_pad: false
random_flip_prob: 0.5

# Accelerator
accelerator: auto
device: auto
distributed: false

# W&B
wandb: true
wandb_offline: false
wandb_project: "jetformer-flow-only-cifar10"
wandb_run_name: "flow-only-baseline-cifar10"
wandb_tags: ["cifar10", "32x32", "p4", "flow-only", "baseline"]
